Convolutional(
  (convolutional): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fullyconnected): Sequential(
    (0): Linear(in_features=7744, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): Sigmoid()
    (4): Linear(in_features=128, out_features=22, bias=True)
  )
)
 Epoch 1/20
-----------------------------------------------------------------
--- Training Loop --- 
Loss: 3.130562, Acc: 3.1% [    0/14409] 
Loss: 1.340889, Acc: 75.0% [ 6400/14409] 
Loss: 0.799010, Acc: 84.4% [12800/14409] 
Avg Loss: 0.657915, Avg Acc: 63.6% 

 --- Validation Loop --- 
 Loss: 0.605639, Acc: 87.5% [    0/ 3646] 
Avg Loss: 0.642299, Avg Acc: 89.4% 

 --- Confusion Matrix --- 
[[268   0   0   0   0   0   0   0   2   0   0   2   0   0   3   0   0   0   0   0   0]
 [  0 151   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   4   0   0]
 [  1   1  93   0   0   0   2   0   3   0   0   0   0   0   0   0   0   0   0   0   0]
 [  4   0   0  98   2   6   0   0   0   0   0   2   0   0   0   0   0   2  10   0   0]
 [  4   0   0   0 475   0   0   0   0   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   1 158  10   0   6   1   0   0   1   0   1   0   0   0   7   0   0]
 [  0   0   0   0   2   8 128   0   0   0   0   0   0   0   1   0   0   0   0   0   0]
 [  1   1   0   0   0   0   0  71   0   0   0   3   0   0   0   0   0   1   0   1   1]
 [  1   0   0   0   0   9   0   0 241   0   0   0   0   0   0   0   0   0   2   0   0]
 [  0   1   0   0   0   5   0   0   0 102   0   7   2   0   0   0   3   0   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0 259   0   0   0   0   0   0   0   0   0   0]
 [  4   2   1   2   1   0   0   0   0   0   1 150   0   0   0   0   0   0   4   0   4]
 [  0  11   3   3   0   9   8   0   0   7   0   3  68   0   0   0   2   0   2   2   0]
 [  0   4   0  13   2   0   0  11   0   0   0   4   0   8   0   0   0   1   0   7   4]
 [  4   2   0   0   0   2   0   0   0   0   0   0   0   0 168   0   8   0   0   0   0]
 [  0  32   0   0   1   2   0   0   0  15   0   2   6   0   0  34   0   0   5   0   0]
 [  2   0   0   0   0   0   0   0   0   2   0   0   0   0   5   0 154   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   8   0  15  98   0   2   0]
 [  0   1   0   1   0   3   0   0   0   0   0   2   0   0   0   0   0   0 177   0   0]
 [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 219   0]
 [  1   2   0   1   1   0   0   0   0   0   0   9   0   0   0   0   1   0   0   0 141]]

 --- Classification Report --- 
              precision    recall  f1-score   support

           0       0.92      0.97      0.95       275
           1       0.72      0.96      0.83       157
           2       0.96      0.93      0.94       100
           3       0.82      0.79      0.81       124
           4       0.98      0.99      0.98       481
           5       0.78      0.85      0.81       186
           6       0.86      0.92      0.89       139
           8       0.87      0.90      0.88        79
           9       0.96      0.95      0.95       253
          10       0.80      0.83      0.81       123
          11       1.00      1.00      1.00       259
          12       0.81      0.89      0.85       169
          13       0.88      0.58      0.70       118
          14       1.00      0.15      0.26        54
          15       0.90      0.91      0.91       184
          16       1.00      0.35      0.52        97
          17       0.84      0.94      0.89       163
          18       0.96      0.79      0.87       124
          19       0.83      0.96      0.89       184
          20       0.94      0.99      0.97       221
          21       0.94      0.90      0.92       156

    accuracy                           0.89      3646
   macro avg       0.89      0.84      0.84      3646
weighted avg       0.90      0.89      0.89      3646
